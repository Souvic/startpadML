{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#We are defining the NN here which will take only the length of nodes in each of the 3 layers as \n",
    "class NN:\n",
    "    def __init__(self,i,h,o):\n",
    "        self.i=i;\n",
    "        self.o=o;\n",
    "        self.h=h;\n",
    "        self.w1=np.random.normal(0,1,(i+1,h));\n",
    "        self.w2=np.random.normal(0,1,(h+1,o));\n",
    "        self.I=np.zeros((i+1));\n",
    "        self.H=np.zeros((h+1));\n",
    "        self.O=np.zeros((o));\n",
    "    def sigmoid(self,x):\n",
    "        return(1/(1+np.exp(-(x))))\n",
    "    def dsigmoid(self,y):\n",
    "        return(np.multiply(y,(1-y)))\n",
    "    def feedforward(self,inputs):\n",
    "        self.I=np.append(inputs,[1])\n",
    "        #print(self.I.shape)\n",
    "        self.H=np.append(self.sigmoid(np.dot(self.I,self.w1)),[1])\n",
    "        self.O=self.sigmoid(np.dot(self.H,self.w2))\n",
    "        return([self.H,self.O])\n",
    "    def backpropagate(self,inputs,targets,lr=0.001,lossfunc=\"logloss\"):\n",
    "        if(lossfunc==\"squareloss\"):\n",
    "            outputs=self.feedforward(inputs)\n",
    "            hiddens=outputs[0];\n",
    "            outputs=outputs[1];\n",
    "            errorterm2=outputs-targets #actually it is (-error)\n",
    "            w2gradient=np.dot((self.H).reshape(((self.h+1),1)),(errorterm2*self.dsigmoid(outputs)).reshape((1,self.o)))\n",
    "            xgrad=np.multiply(self.w2,(errorterm2*self.dsigmoid(outputs)))\n",
    "            errorterm1=np.sum(xgrad[:-1],axis=1)\n",
    "            w1gradient=np.dot((self.I).reshape(((self.i+1),1)),(errorterm1*self.dsigmoid(hiddens[:-1])).reshape((1,self.h)))\n",
    "        elif(lossfunc==\"logloss\"):\n",
    "            outputs=self.feedforward(inputs)\n",
    "            hiddens=outputs[0];\n",
    "            outputs=outputs[1];\n",
    "            errorterm2=0-targets/(0.0001+outputs)+(1-targets)/(1.0001-outputs) #actually it is (-error)... 0.0001 is added to avoid hitting infinity\n",
    "            w2gradient=np.dot((self.H).reshape(((self.h+1),1)),(errorterm2*self.dsigmoid(outputs)).reshape((1,self.o)))\n",
    "            xgrad=np.multiply(self.w2,(errorterm2*self.dsigmoid(outputs)))\n",
    "            errorterm1=np.sum(xgrad[:-1],axis=1)\n",
    "            w1gradient=np.dot((self.I).reshape(((self.i+1),1)),(errorterm1*self.dsigmoid(hiddens[:-1])).reshape((1,self.h)))\n",
    "   \n",
    "        #update step\n",
    "        self.w1=self.w1-w1gradient*lr;\n",
    "        self.w2=self.w2-w2gradient*lr;\n",
    "    def train(self,inputs,targets,lr=0.001,niter=1000,lossfunc=\"logloss\"):\n",
    "        for u in range(niter):\n",
    "            for row in range(len(inputs)):\n",
    "                self.backpropagate(inputs[row],targets[row],lr,lossfunc)\n",
    "            self.evaluate(inputs,targets,lossfunc)\n",
    "            \n",
    "    def evaluate(self,inputs,targets,lossfunc=\"logloss\"):\n",
    "        if(lossfunc==\"squareloss\"):\n",
    "            print(np.mean(([np.square(self.feedforward(inputs[ii])[1]-targets[ii]) for ii in range(len(inputs))])))\n",
    "            print(\"   *****error printed***** \")\n",
    "        elif(lossfunc==\"logloss\"):\n",
    "            print(np.mean(([np.square(self.feedforward(inputs[ii])[1]-targets[ii]) for ii in range(len(inputs))])))\n",
    "            print(\"   *****error printed***** \")\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=NN(2,5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ins=np.random.randint(0,2,(4000,2))\n",
    "outs=np.array([[g[0]*g[1],(g[0]+g[1]>0)*1] for g in ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00162436449696\n",
      "   *****error printed***** \n",
      "0.000646099418856\n",
      "   *****error printed***** \n",
      "0.000390682500925\n",
      "   *****error printed***** \n",
      "0.00027669592903\n",
      "   *****error printed***** \n",
      "0.000212908552547\n",
      "   *****error printed***** \n",
      "0.000172396017692\n",
      "   *****error printed***** \n",
      "0.000144490381554\n",
      "   *****error printed***** \n",
      "0.000124150593622\n",
      "   *****error printed***** \n",
      "0.00010869477713\n",
      "   *****error printed***** \n",
      "9.65686033664e-05\n",
      "   *****error printed***** \n",
      "8.68108197803e-05\n",
      "   *****error printed***** \n",
      "7.87958650359e-05\n",
      "   *****error printed***** \n",
      "7.20995467743e-05\n",
      "   *****error printed***** \n",
      "6.64243029203e-05\n",
      "   *****error printed***** \n",
      "6.1555379881e-05\n",
      "   *****error printed***** \n",
      "5.73339918629e-05\n",
      "   *****error printed***** \n",
      "5.36402619141e-05\n",
      "   *****error printed***** \n",
      "5.03820303676e-05\n",
      "   *****error printed***** \n",
      "4.74873076053e-05\n",
      "   *****error printed***** \n",
      "4.48990601161e-05\n",
      "   *****error printed***** \n"
     ]
    }
   ],
   "source": [
    "model.train(ins,outs,0.5,20,\"squareloss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.44910980478e-06\n",
      "   *****error printed***** \n",
      "1.13107953975e-06\n",
      "   *****error printed***** \n",
      "4.6005458597e-07\n",
      "   *****error printed***** \n",
      "2.44670966884e-07\n",
      "   *****error printed***** \n",
      "1.50407552678e-07\n",
      "   *****error printed***** \n",
      "1.01247517461e-07\n",
      "   *****error printed***** \n",
      "7.25329977389e-08\n",
      "   *****error printed***** \n",
      "5.43733219828e-08\n",
      "   *****error printed***** \n",
      "4.21919524357e-08\n",
      "   *****error printed***** \n",
      "3.3640920502e-08\n",
      "   *****error printed***** \n",
      "2.74174149589e-08\n",
      "   *****error printed***** \n",
      "2.2752595616e-08\n",
      "   *****error printed***** \n",
      "1.9169570746e-08\n",
      "   *****error printed***** \n",
      "1.63601199906e-08\n",
      "   *****error printed***** \n",
      "1.41180352106e-08\n",
      "   *****error printed***** \n",
      "1.23012348437e-08\n",
      "   *****error printed***** \n",
      "1.08093031287e-08\n",
      "   *****error printed***** \n",
      "9.56968239453e-09\n",
      "   *****error printed***** \n",
      "8.52891321952e-09\n",
      "   *****error printed***** \n",
      "7.64692139739e-09\n",
      "   *****error printed***** \n"
     ]
    }
   ],
   "source": [
    "model2=NN(2,5,2)\n",
    "model2.train(ins,outs,0.5,20,\"logloss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
